{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json \n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from velopix_wrappers.parameter_optimisers import optimiserBase\n",
    "from velopix_wrappers.velopix_pipeline import TrackFollowingPipeline, GraphDFSPipeline, SearchByTripletTriePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the optimiser child class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random \n",
    "\n",
    "class ParticleSwarm(optimiserBase):\n",
    "    def __init__(self,\n",
    "        swarm_size: int = 10,\n",
    "        w: float = 0.5,\n",
    "        c1: float = 1.5,\n",
    "        c2: float = 1.5,\n",
    "        convergence_tolerance: float = 1e-4,\n",
    "        patience: int = 15,\n",
    "        **kwargs):\n",
    "        super().__init__(Objective=\"min\")\n",
    "        self.swarm_size = swarm_size\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.convergence_tolerance = convergence_tolerance\n",
    "        self.patience = patience\n",
    "\n",
    "        # These attributes will be set during init()\n",
    "        self.swarm = []         # List of particle positions (each a dict)\n",
    "        self.velocities = []    # List of particle velocities (dicts matching the particle structure)\n",
    "        self.pbest = []         # Personal best positions for each particle\n",
    "        self.pbest_scores = []  # Best scores for each particle\n",
    "        self.iterations = 0\n",
    "        self.current_particle_index = 0  # Which particle's turn to be updated/evaluated\n",
    "        self.score_history = []\n",
    "\n",
    "    def is_finished(self):\n",
    "        if len(self.score_history) > self.patience:\n",
    "            recent_scores = self.score_history[-self.patience:]\n",
    "            improvement = max(recent_scores) - min(recent_scores)\n",
    "            if improvement < self.convergence_tolerance:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def init(self):\n",
    "        schema = self._algorithm.get_config() # get the schema for the track reconstruction algo \n",
    "\n",
    "        self.swarm = []\n",
    "        self.velocities = []\n",
    "        self.pbest = []\n",
    "        self.pbest_scores = []\n",
    "        self.score_history = []\n",
    "\n",
    "        for _ in range(self.swarm_size):\n",
    "            particle = {}\n",
    "            velocity = {}\n",
    "            for key, (expected_type, _) in schema.items():\n",
    "                # init bools at random\n",
    "                if expected_type == bool:\n",
    "                    particle[key] = random.choice([True, False])\n",
    "                    velocity[key] = 0.0\n",
    "                elif expected_type == float or expected_type == int:\n",
    "                    low, high = self._algorithm._bounds().get(key)\n",
    "                    particle[key] = expected_type(random.uniform(low, high))\n",
    "                velocity[key] = 0.0\n",
    "\n",
    "            self.swarm.append(particle)\n",
    "            self.velocities.append(velocity)\n",
    "            self.pbest.append(deepcopy(particle))\n",
    "            self.pbest_scores.append(float(\"inf\"))\n",
    "\n",
    "        self.best_score = float(\"inf\")\n",
    "        self.best_config = deepcopy(self.swarm[0])\n",
    "        self.iterations = 0\n",
    "        self.current_particle_index = 0\n",
    "        return deepcopy(self.swarm[0])\n",
    "    \n",
    "    def next(self):\n",
    "        # Cycle to the next particle in the swarm, since we need to eval each particle at the time in the algo's\n",
    "        self.current_particle_index = (self.current_particle_index + 1) % self.swarm_size\n",
    "        idx = self.current_particle_index\n",
    "        schema = self._algorithm.get_config()\n",
    "\n",
    "        for key, (expected_type, _) in schema.items():\n",
    "            if expected_type == bool:\n",
    "                # note sure what to do here yet\n",
    "                continue \n",
    "\n",
    "            low, high = self._algorithm._bounds().get(key)\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            current_vel = self.velocities[idx][key]\n",
    "            current_pos = self.swarm[idx][key]\n",
    "            pbest_pos = self.pbest[idx][key]\n",
    "            gbest_contrib = 0.0 if self.best_score == float(\"inf\") else self.best_config[key] - current_pos\n",
    "\n",
    "            new_vel = (\n",
    "                self.w * current_vel +\n",
    "                self.c1 * r1 * (pbest_pos - current_pos) +\n",
    "                self.c2 * r2 * gbest_contrib\n",
    "            )\n",
    "            self.velocities[idx][key] = new_vel\n",
    "\n",
    "            new_pos = current_pos + new_vel\n",
    "            new_pos = max(low, min(new_pos, high))\n",
    "            self.swarm[idx][key] = expected_type(new_pos)\n",
    "\n",
    "        self.iterations += 1\n",
    "        candidate = deepcopy(self.swarm[idx])\n",
    "\n",
    "        candidate_score = self.objective_func() # We're minimising the score\n",
    "        idx = self.current_particle_index\n",
    "        self.score_history.append(candidate_score)\n",
    "\n",
    "        if candidate_score < self.pbest_scores[idx]:\n",
    "            self.pbest_scores[idx] = candidate_score\n",
    "            self.pbest[idx] = deepcopy(self.swarm[idx])\n",
    "\n",
    "        if candidate_score < self.best_score:\n",
    "            self.best_score = candidate_score\n",
    "            self.best_config = deepcopy(self.swarm[idx])\n",
    "\n",
    "        return candidate\n",
    "    \n",
    "    def objective_func(self): # we can generate custom objective functions here or use a standard defined objective function \n",
    "        return self.event_objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load event data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: velo_event_0.json\n",
      "Loading file: velo_event_1.json\n",
      "Loading file: velo_event_2.json\n",
      "Loading file: velo_event_3.json\n",
      "Loading file: velo_event_4.json\n",
      "Loading file: velo_event_5.json\n",
      "Loading file: velo_event_6.json\n",
      "Loading file: velo_event_7.json\n",
      "Loading file: velo_event_8.json\n",
      "Loading file: velo_event_9.json\n",
      "Loading file: velo_event_10.json\n",
      "Loading file: velo_event_11.json\n",
      "Loading file: velo_event_12.json\n",
      "Loading file: velo_event_13.json\n",
      "Loading file: velo_event_14.json\n",
      "Loading file: velo_event_15.json\n",
      "Loading file: velo_event_16.json\n",
      "Loading file: velo_event_17.json\n",
      "Loading file: velo_event_18.json\n",
      "Loading file: velo_event_19.json\n",
      "Loading file: velo_event_20.json\n",
      "Loading file: velo_event_21.json\n",
      "Loading file: velo_event_22.json\n",
      "Loading file: velo_event_23.json\n",
      "Loading file: velo_event_24.json\n",
      "Loading file: velo_event_25.json\n",
      "Loading file: velo_event_26.json\n",
      "Loading file: velo_event_27.json\n",
      "Loading file: velo_event_28.json\n",
      "Loading file: velo_event_29.json\n",
      "Loading file: velo_event_30.json\n",
      "Loading file: velo_event_31.json\n",
      "Loading file: velo_event_32.json\n",
      "Loading file: velo_event_33.json\n",
      "Loading file: velo_event_34.json\n",
      "Loading file: velo_event_35.json\n",
      "Loading file: velo_event_36.json\n",
      "Loading file: velo_event_37.json\n",
      "Loading file: velo_event_38.json\n",
      "Loading file: velo_event_39.json\n",
      "Loading file: velo_event_40.json\n",
      "Loading file: velo_event_41.json\n",
      "Loading file: velo_event_42.json\n",
      "Loading file: velo_event_43.json\n",
      "Loading file: velo_event_44.json\n",
      "Loading file: velo_event_45.json\n",
      "Loading file: velo_event_46.json\n",
      "Loading file: velo_event_47.json\n",
      "Loading file: velo_event_48.json\n",
      "Loading file: velo_event_49.json\n",
      "Loading file: velo_event_50.json\n",
      "Skipping problematic file: velo_event_51.json\n",
      "Loading file: velo_event_52.json\n",
      "Loading file: velo_event_53.json\n",
      "Loading file: velo_event_54.json\n",
      "Loading file: velo_event_55.json\n",
      "Loading file: velo_event_56.json\n",
      "Loading file: velo_event_57.json\n",
      "Loading file: velo_event_58.json\n",
      "Loading file: velo_event_59.json\n",
      "Loading file: velo_event_60.json\n",
      "Loading file: velo_event_61.json\n",
      "Loading file: velo_event_62.json\n",
      "Loading file: velo_event_63.json\n",
      "Loading file: velo_event_64.json\n",
      "Loading file: velo_event_65.json\n",
      "Loading file: velo_event_66.json\n",
      "Loading file: velo_event_67.json\n",
      "Loading file: velo_event_68.json\n",
      "Loading file: velo_event_69.json\n",
      "Loading file: velo_event_70.json\n",
      "Loading file: velo_event_71.json\n",
      "Loading file: velo_event_72.json\n",
      "Loading file: velo_event_73.json\n",
      "Loading file: velo_event_74.json\n",
      "Loading file: velo_event_75.json\n",
      "Loading file: velo_event_76.json\n",
      "Loading file: velo_event_77.json\n",
      "Loading file: velo_event_78.json\n",
      "Loading file: velo_event_79.json\n",
      "Loading file: velo_event_80.json\n",
      "Loading file: velo_event_81.json\n",
      "Loading file: velo_event_82.json\n",
      "Loading file: velo_event_83.json\n",
      "Loading file: velo_event_84.json\n",
      "Loading file: velo_event_85.json\n",
      "Loading file: velo_event_86.json\n",
      "Loading file: velo_event_87.json\n",
      "Loading file: velo_event_88.json\n",
      "Loading file: velo_event_89.json\n",
      "Loading file: velo_event_90.json\n",
      "Loading file: velo_event_91.json\n",
      "Loading file: velo_event_92.json\n",
      "Loading file: velo_event_93.json\n",
      "Loading file: velo_event_94.json\n",
      "Loading file: velo_event_95.json\n",
      "Loading file: velo_event_96.json\n",
      "Loading file: velo_event_97.json\n",
      "Loading file: velo_event_98.json\n",
      "Loading file: velo_event_99.json\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "n_files = 100\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data)\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_pipeline = TrackFollowingPipeline(events=events, intra_node=False)\n",
    "Graph_pipeline = GraphDFSPipeline(events=events, intra_node=False)\n",
    "Triplet_pipeline = SearchByTripletTriePipeline(events=events, intra_node=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = ParticleSwarm(\n",
    "    swarm_size=2,\n",
    "    w=0.1,\n",
    "    c1=0.25,\n",
    "    c2=0.3,\n",
    "    convergence_tolerance=1e-3,\n",
    "    patience=7\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters_TF = TF_pipeline.optimise_parameters(Optimiser, max_runs=10) # DO NOT remove max_runs, chances are that this will run forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimal_parameters_Graph = Graph_pipeline.optimise_parameters(Optimiser, max_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters_Triplet = Triplet_pipeline.optimise_parameters(Optimiser, max_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Optimiser.get_optimised_pMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_slope': 70.40756777753698, 'y_slope': 33.813617985698905, 'x_tol': 1.8339073102118497, 'y_tol': 5.974312516342821, 'scatter': 3.5862934522445915}\n"
     ]
    }
   ],
   "source": [
    "print(optimal_parameters_TF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
