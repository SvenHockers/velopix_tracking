{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6db58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from velopix_wrappers.optimizers import BaseOptimizer\n",
    "from velopix_wrappers.velopix_pipeline import TrackFollowingPipeline, GraphDFSPipeline, SearchByTripletTriePipeline\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Dict, Literal, List\n",
    "import random\n",
    "import numpy as np\n",
    "from velopix_wrappers.optimizers import BaseOptimizer, pMap\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbdfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, bounds, parent: Any = None):\n",
    "        self.sum_reward = 0\n",
    "        self.visited = 0\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        self.bounds = bounds\n",
    "\n",
    "    def add_child(self, child: Any):\n",
    "        self.children.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return pmap based on bounds (split in middle) (rollout phase)\n",
    "def returnPmap (bounds: Dict[str, Any], cfg: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    new_pmap = {}\n",
    "    \n",
    "    for key, (typ, _) in cfg.items():\n",
    "        if typ is float:\n",
    "            new_pmap[key] = (bounds[key][0] + bounds[key][1]) / 2\n",
    "        elif typ is int:\n",
    "            new_pmap[key] = (int)((bounds[key][0] + bounds[key][1]) / 2)\n",
    "        elif typ is bool:\n",
    "            new_pmap[key] = bounds[key]\n",
    "        \n",
    "    return new_pmap\n",
    "\n",
    "\n",
    "def returnBounds (bounds: Dict[str, Any], cfg: Dict[str, Any]) -> List [Dict[str, Any]]: #TODO we currently split each of the bounds in half but we only want to split the axis with the \n",
    "                                                                                        # currently largest diameter, also its late my brain is cooked but should we skip over the keys that \n",
    "                                                                                        # are boolean as we currently try to split these? we also never noremalize anywhere.\n",
    "\n",
    "    map = returnPmap(bounds, cfg)\n",
    "    new_bounds = [deepcopy(bounds), deepcopy(bounds)]\n",
    "\n",
    "    \n",
    "    for key, (typ, _) in cfg.items():\n",
    "        new_bounds[0][key][1] = map[key]\n",
    "        new_bounds[1][key][0] = map[key]\n",
    "        \n",
    "        \n",
    "    return new_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyHoot(BaseOptimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int = 100,\n",
    "        objective: Literal[\"min\", \"max\"] = \"min\"\n",
    "    ):\n",
    "        super().__init__(objective=objective, auto_eval={\"autoEval\": True, \"nested\": True, \"weights\": [1.0, 1.0, 1.0, -10.0]})\n",
    "        self.max_iterations = max_iterations\n",
    "        self.current_iteration = 0\n",
    "\n",
    "        self.alfa = 5\n",
    "        self.epsilon = 20\n",
    "        self.eta = 0.5\n",
    "\n",
    "\n",
    "        self.cfg = self._algorithm.get_config()\n",
    "        self.bounds = self._algorithm.get_bounds()\n",
    "\n",
    "        self.root = Node(bounds=self.bounds)  # Root node with no bounds\n",
    "        self.nodes = [self.root]\n",
    "        self.current_node = self.root\n",
    "\n",
    "        self.param_num = 0\n",
    "\n",
    "        for key, (typ, _) in self.cfg.items():\n",
    "            if typ is not bool:\n",
    "                self.param_num += 1\n",
    "\n",
    "        self.nu = 4 * self.param_num\n",
    "        self.ro = 1 / (4 * self.param_num)\n",
    "\n",
    "\n",
    "    def init(self) -> pMap:\n",
    "        \"\"\"\n",
    "        Initializes with a random point within bounds.\n",
    "        \"\"\"\n",
    "        self.current_iteration += 1\n",
    "\n",
    "        #pregenerate trees of bounds\n",
    "        for key, (typ, _) in self.cfg.items():\n",
    "            if typ is bool:\n",
    "                current_leaves = [node for node in self.nodes if len(node.children) == 0]\n",
    "                for node in current_leaves: # I think this is an infite loop no since we keep adding nodes to the nodes list in the loop we keep adding children forever no?\n",
    "                    #also changed logic since we were overriding the original bounds.\n",
    "                    bounds_false = deepcopy(node.bounds)\n",
    "                    bounds_false[key] = 0 #TODO should this be an int or a true bool to ask group..\n",
    "                    node1 = Node(bounds=bounds_false, parent=node)\n",
    "                    \n",
    "                    bounds_true = deepcopy(node.bounds)\n",
    "                    bounds_true[key] = 1 #TODO should this be an int or a true bool to ask group..\n",
    "                    node2 = Node(bounds=bounds_true, parent=node)\n",
    "                    \n",
    "                    #I think we also want to add these as children to the parent node yeah? or in this case the current node\n",
    "                    node.children.append(node1)\n",
    "                    node.children.append(node2)\n",
    "                    \n",
    "                    #leave unchanged..\n",
    "                    self.nodes.append(node1)\n",
    "                    self.nodes.append(node2)\n",
    "\n",
    "\n",
    "        node = self.root\n",
    "        depth = 0\n",
    "\n",
    "        while len(node.children):\n",
    "            node.visited += 1\n",
    "            node = node.children[0]\n",
    "            depth += 1\n",
    "\n",
    "\n",
    "        node.visited += 1\n",
    "\n",
    "        new_bounds = returnBounds(node.bounds, self.cfg)\n",
    "\n",
    "        node.add_child(Node(bounds=new_bounds[0], parent=node))\n",
    "        node.add_child(Node(bounds=new_bounds[1], parent=node))\n",
    "\n",
    "\n",
    "        pmap = returnPmap(node.bounds, self.cfg)\n",
    "\n",
    "        return pmap\n",
    "    \n",
    "\n",
    "\n",
    "    def next(self) -> pMap:\n",
    "        \"\"\"\n",
    "        Evaluates the current configuration and returns a new one.\n",
    "        \"\"\"\n",
    "        self.current_iteration += 1\n",
    "\n",
    "        # Evaluate the current configuration (from previous init/next call)\n",
    "        #score = self.objective_func([1.0, 1.0, 1.0, -10.0])\n",
    "        #so we already increased the count of the nodes but we still want to backprop the scors which should happen after a run so at the start of \n",
    "        # next we get the last score in history and trace back up the stack accordingly or just use the score above but faster to get the score from history??? TODO ask team\n",
    "        #TODO:backprop here FIXED?!?!\n",
    "        if hasattr(self, 'score_history') and len(self.score_history) > 0:\n",
    "            score = self.score_history[-1]\n",
    "            current = self.current_node\n",
    "            while current is not None:\n",
    "                current.sum_reward += score\n",
    "                current = current.parent\n",
    "        \n",
    "        node = self.root\n",
    "        depth = 0\n",
    "\n",
    "        while len(node.children):\n",
    "            node.visited += 1\n",
    "            if node.children[0].visited == 0:\n",
    "                node = node.children[0]\n",
    "            elif node.children[1].visited == 0:\n",
    "                node = node.children[1]\n",
    "            else:\n",
    "                node1_score = (node.children[0].sum_reward / node.children[0].visited) + (self.current_iteration ** (self.alfa/self.epsilon)) * (node.children[0].visited ** (self.eta - 1)) + (self.nu * (self.ro ** depth))\n",
    "                node2_score = (node.children[1].sum_reward / node.children[1].visited) + (self.current_iteration ** (self.alfa/self.epsilon)) * (node.children[1].visited ** (self.eta - 1)) + (self.nu * (self.ro ** depth))\n",
    "\n",
    "                if node1_score > node2_score:\n",
    "                    node = node.children[0]\n",
    "                else:\n",
    "                    node = node.children[1]\n",
    "\n",
    "            depth += 1\n",
    "\n",
    "        node.visited += 1\n",
    "\n",
    "        new_bounds = returnBounds(node.bounds, self.cfg)\n",
    "\n",
    "        node.add_child(Node(bounds=new_bounds[0], parent=node))\n",
    "        node.add_child(Node(bounds=new_bounds[1], parent=node))\n",
    "\n",
    "\n",
    "        pmap = returnPmap(node.bounds, self.cfg)\n",
    "        #keep track of the leaf node we expanded and rolled out for the backprop we we do next again.\n",
    "        self.current_node = node\n",
    "\n",
    "            \n",
    "        return pmap\n",
    "    \n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        \"\"\"Determines if optimization is complete.\"\"\"\n",
    "        #TODO: possibly add a check for reaching target score\n",
    "        #TODO check with team but I think here we also want to perform backprop since if were finished we wont performn the last next we need to backprop so we do it here instead\n",
    "        finished = self.current_iteration >= self.max_iterations\n",
    "        if finished:\n",
    "            if hasattr(self, 'score_history') and len(self.score_history) > 0:\n",
    "                score = self.score_history[-1]\n",
    "                current = self.current_node\n",
    "                while current is not None:\n",
    "                    current.sum_reward += score\n",
    "                    current = current.parent\n",
    "                \n",
    "        return finished\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "n_files = 150\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data) # type: ignore\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrackFollowingPipeline(events=events, intra_node=True) # type: ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = PolyHoot(max_iterations=243, objective=\"min\") # type: ignore\n",
    "optimal_parameters = pipeline.optimise_parameters(Optimiser, max_runs=2430) # DO NOT remove max_runs, chances are that this will run forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_parameters) # Note these are just here for example..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
