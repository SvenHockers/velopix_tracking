{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json \n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from velopix.hyperParameterFramework._optimizers import BaseOptimizer, pMap\n",
    "from velopix.hyperParameterFramework import TrackFollowingPipeline, GraphDFSPipeline, SearchByTripletTriePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the optimiser child class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Literal, List\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class ParticleSwarm(BaseOptimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        swarm_size: int = 20,\n",
    "        inertia: float = 0.5,\n",
    "        cognitive: float = 1.5,\n",
    "        social: float = 1.5,\n",
    "        max_iterations: int = 100,\n",
    "        objective: Literal[\"min\", \"max\"] = \"min\",\n",
    "        nested: bool = False,\n",
    "        weights: list[float] = [1.0, 1.0, 1.0, -10.0]\n",
    "    ):\n",
    "        super().__init__(objective=objective)\n",
    "        self.swarm_size = swarm_size\n",
    "        self.inertia = inertia\n",
    "        self.cognitive = cognitive\n",
    "        self.social = social\n",
    "        self.max_iterations = max_iterations\n",
    "        self.current_iteration = 0\n",
    "        self.nested = nested\n",
    "        self.weights = weights\n",
    "        self.target_score: float = (\n",
    "            float(\"inf\") if self.objective == \"max\" else float(\"-inf\")\n",
    "        )\n",
    "\n",
    "        # PSO state:\n",
    "        self.swarm: List[Dict[str, Any]] = []              # Current positions\n",
    "        self.velocities: List[Dict[str, float]] = []       # Velocities for each particle\n",
    "        self.pbest_positions: List[Dict[str, Any]] = []    # Personal best positions\n",
    "        self.pbest_scores: List[float] = []                # Personal best scores\n",
    "        self.gbest_position: Dict[str, Any] = {}           # Global best position\n",
    "        self.gbest_score: float = (\n",
    "            float(\"inf\") if self.objective == \"min\" else float(\"-inf\")\n",
    "        )\n",
    "\n",
    "        # Bookkeeping for stepping through the swarm one‐by‐one\n",
    "        self.current_particle_index: int = 0\n",
    "        self._current_config: pMap = None\n",
    "        self._stopped = False\n",
    "\n",
    "    def init(self) -> pMap:\n",
    "        \"\"\"\n",
    "        - Initialize the swarm (positions + velocities).\n",
    "        - Set personal best = initial positions.\n",
    "        - Find initial global best among the swarm.\n",
    "        - Return the first particles configuration for evaluation.\n",
    "        \"\"\"\n",
    "        self._stopped = False\n",
    "        self.current_iteration = 0\n",
    "        self.swarm.clear()\n",
    "        self.velocities.clear()\n",
    "        self.pbest_positions.clear()\n",
    "        self.pbest_scores.clear()\n",
    "        self.gbest_position = {}\n",
    "        self.gbest_score = float(\"inf\") if self.objective == \"min\" else float(\"-inf\")\n",
    "        self.current_particle_index = 0\n",
    "\n",
    "        # Step 1: build swarm and velocities\n",
    "        cfg = self._algorithm.get_config()\n",
    "        bds = self._algorithm.get_bounds()\n",
    "\n",
    "        for _ in range(self.swarm_size):\n",
    "            pos = {}\n",
    "            vel = {}\n",
    "\n",
    "            # Randomly sample each dimension for position and velocity\n",
    "            for key, (typ, _) in cfg.items():\n",
    "                bounds = bds.get(key)\n",
    "                if bounds is None:\n",
    "                    continue\n",
    "                low, high = bounds\n",
    "\n",
    "                if typ is float:\n",
    "                    # Position uniformly in [low,high]\n",
    "                    pos[key] = random.uniform(low, high)\n",
    "                    # Velocity uniform in [-(high-low), +(high-low)]\n",
    "                    vel[key] = random.uniform(-(high - low), (high - low))\n",
    "                elif typ is int:\n",
    "                    pos[key] = random.randint(int(low), int(high))\n",
    "                    vel[key] = random.uniform(-(high - low), (high - low))\n",
    "                elif typ is bool:\n",
    "                    pos[key] = random.choice([True, False])\n",
    "                    vel[key] = 0.0\n",
    "                elif typ is list:\n",
    "                    # categorical: pick one at random; no velocity\n",
    "                    pos[key] = random.choice(bounds if isinstance(bounds, list) else [])\n",
    "                    vel[key] = 0.0\n",
    "\n",
    "            self.swarm.append(pos)\n",
    "            self.velocities.append(vel)\n",
    "\n",
    "        # Step 2: initialize personal bests to the same as positions, scores unknown yet\n",
    "        # We'll use +inf (for min) or -inf (for max) to force an update on first evaluation.\n",
    "        initial_pbest_score = float(\"inf\") if self.objective == \"min\" else float(\"-inf\")\n",
    "        for _ in range(self.swarm_size):\n",
    "            self.pbest_positions.append({})\n",
    "            self.pbest_scores.append(initial_pbest_score)\n",
    "\n",
    "        # Step 3: Set the first particle to be evaluated next\n",
    "        self._current_config = self.swarm[0]\n",
    "        return self._current_config\n",
    "\n",
    "    def next(self) -> pMap:\n",
    "        \"\"\"\n",
    "        - Evaluates the current particle (self._current_config).\n",
    "        - Updates personal best for that particle, updates global best if needed.\n",
    "        - Advances to the next particle index. If the entire swarm has just been evaluated,\n",
    "          perform a PSO velocity + position update, increment iteration count, and reset index.\n",
    "        - Return the new config for evaluation.\n",
    "        \"\"\"\n",
    "        # 1) Evaluate current particle\n",
    "        score = self.objective_func(self.weights, self.nested)\n",
    "        \n",
    "        # Store data\n",
    "        self.score_history.append(score)\n",
    "\n",
    "        i = self.current_particle_index\n",
    "        # Update personal best if this is better\n",
    "        if self.pbest_positions[i] is None or self.pbest_positions[i] == {}:\n",
    "            # First‐time initialization of pbest\n",
    "            self.pbest_positions[i] = self._current_config.copy()\n",
    "            self.pbest_scores[i] = score\n",
    "        else:\n",
    "            if self.objective == \"min\":\n",
    "                if score < self.pbest_scores[i]:\n",
    "                    self.pbest_scores[i] = score\n",
    "                    self.pbest_positions[i] = self._current_config.copy()\n",
    "            else:  # \"max\"\n",
    "                if score > self.pbest_scores[i]:\n",
    "                    self.pbest_scores[i] = score\n",
    "                    self.pbest_positions[i] = self._current_config.copy()\n",
    "\n",
    "        # Update global best if needed\n",
    "        if self.objective == \"min\":\n",
    "            if score < self.gbest_score:\n",
    "                self.gbest_score = score\n",
    "                self.gbest_position = self._current_config.copy()\n",
    "        else:\n",
    "            if score > self.gbest_score:\n",
    "                self.gbest_score = score\n",
    "                self.gbest_position = self._current_config.copy()\n",
    "\n",
    "        # 2) Advance to next particle (or, if end of swarm, perform a PSO update)\n",
    "        self.current_particle_index += 1\n",
    "\n",
    "        if self.current_particle_index >= self.swarm_size:\n",
    "            # We have finished evaluating all particles in this iteration\n",
    "            # Check stopping criteria before updating\n",
    "            if (\n",
    "                (self.objective == \"min\" and self.gbest_score <= self.target_score)\n",
    "                or (self.objective == \"max\" and self.gbest_score >= self.target_score)\n",
    "            ):\n",
    "                self._stopped = True\n",
    "\n",
    "            # If we still have iterations left, update velocities & positions\n",
    "            if self.current_iteration < self.max_iterations and not self._stopped:\n",
    "                self._update_velocities_positions()\n",
    "                self.current_iteration += 1\n",
    "                self.current_particle_index = 0\n",
    "            else:\n",
    "                self._stopped = True\n",
    "\n",
    "        # 3) Prepare the next config to evaluate\n",
    "        if not self._stopped:\n",
    "            self._current_config = self.swarm[self.current_particle_index]\n",
    "        return self._current_config\n",
    "\n",
    "    def _update_velocities_positions(self):\n",
    "        \"\"\"\n",
    "        After a full pass of evaluations, update each particle's velocity & position:\n",
    "        v <- w*v + c1*r1*(pbest - pos) + c2*r2*(gbest - pos)\n",
    "        pos ← pos + v\n",
    "        For non numeric types (bool, list), we simply resample randomly each update.\n",
    "        \"\"\"\n",
    "        cfg = self._algorithm.get_config()\n",
    "        bds = self._algorithm.get_bounds()\n",
    "\n",
    "        for i in range(self.swarm_size):\n",
    "            pos = self.swarm[i]\n",
    "            vel = self.velocities[i]\n",
    "            pbest = self.pbest_positions[i]\n",
    "            # Fallback if pbest is missing (should only occur before first evaluation)\n",
    "            if not pbest:\n",
    "                pbest = pos\n",
    "\n",
    "            for key, (typ, _) in cfg.items():\n",
    "                bounds = bds.get(key)\n",
    "                if bounds is None:\n",
    "                    continue\n",
    "                low, high = bounds\n",
    "\n",
    "                if typ is float:\n",
    "                    # Retrieve current float position & velocity\n",
    "                    x = float(pos[key])\n",
    "                    v = float(vel.get(key, 0.0))\n",
    "                    pbest_x = float(pbest[key])\n",
    "                    gbest_x = float(self.gbest_position[key])\n",
    "\n",
    "                    r1 = random.random()\n",
    "                    r2 = random.random()\n",
    "\n",
    "                    # PSO velocity update for float\n",
    "                    new_v = (\n",
    "                        self.inertia * v\n",
    "                        + self.cognitive * r1 * (pbest_x - x)\n",
    "                        + self.social * r2 * (gbest_x - x)\n",
    "                    )\n",
    "\n",
    "                    # Update position and clamp\n",
    "                    x_new = x + new_v\n",
    "                    x_new = max(min(x_new, high), low)\n",
    "\n",
    "                    # Write back as float\n",
    "                    pos[key] = float(x_new)\n",
    "                    vel[key] = new_v\n",
    "\n",
    "                elif typ is int:\n",
    "                    # Retrieve current int position as float & velocity\n",
    "                    x = float(pos[key])\n",
    "                    v = float(vel.get(key, 0.0))\n",
    "                    pbest_x = float(pbest[key])\n",
    "                    gbest_x = float(self.gbest_position[key])\n",
    "\n",
    "                    r1 = random.random()\n",
    "                    r2 = random.random()\n",
    "\n",
    "                    # PSO velocity update for int\n",
    "                    new_v = (\n",
    "                        self.inertia * v\n",
    "                        + self.cognitive * r1 * (pbest_x - x)\n",
    "                        + self.social * r2 * (gbest_x - x)\n",
    "                    )\n",
    "\n",
    "                    # Update position and clamp in float space\n",
    "                    x_new = x + new_v\n",
    "                    x_new = max(min(x_new, high), low)\n",
    "\n",
    "                    # Round & clamp to integer\n",
    "                    x_new_int = int(round(x_new))\n",
    "                    x_new_int = max(min(x_new_int, int(high)), int(low))\n",
    "\n",
    "                    pos[key] = x_new_int\n",
    "                    vel[key] = new_v\n",
    "\n",
    "                elif typ is bool:\n",
    "                    # No velocity for boolean; resample randomly each iteration\n",
    "                    pos[key] = random.choice([True, False])\n",
    "                    vel[key] = 0.0\n",
    "\n",
    "                elif typ is list:\n",
    "                    # Categorical: pick a random choice each iteration\n",
    "                    options = bounds if isinstance(bounds, list) else []\n",
    "                    if options:\n",
    "                        pos[key] = random.choice(options)\n",
    "                    vel[key] = 0.0\n",
    "\n",
    "            # Save updates back into swarm and velocities lists\n",
    "            self.swarm[i] = pos\n",
    "            self.velocities[i] = vel\n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        return self._stopped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load event data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: velo_event_0.json\n",
      "Loading file: velo_event_1.json\n",
      "Loading file: velo_event_2.json\n",
      "Loading file: velo_event_3.json\n",
      "Loading file: velo_event_4.json\n",
      "Loading file: velo_event_5.json\n",
      "Loading file: velo_event_6.json\n",
      "Loading file: velo_event_7.json\n",
      "Loading file: velo_event_8.json\n",
      "Loading file: velo_event_9.json\n",
      "Loading file: velo_event_10.json\n",
      "Loading file: velo_event_11.json\n",
      "Loading file: velo_event_12.json\n",
      "Loading file: velo_event_13.json\n",
      "Loading file: velo_event_14.json\n",
      "Loading file: velo_event_15.json\n",
      "Loading file: velo_event_16.json\n",
      "Loading file: velo_event_17.json\n",
      "Loading file: velo_event_18.json\n",
      "Loading file: velo_event_19.json\n",
      "Loading file: velo_event_20.json\n",
      "Loading file: velo_event_21.json\n",
      "Loading file: velo_event_22.json\n",
      "Loading file: velo_event_23.json\n",
      "Loading file: velo_event_24.json\n",
      "Loading file: velo_event_25.json\n",
      "Loading file: velo_event_26.json\n",
      "Loading file: velo_event_27.json\n",
      "Loading file: velo_event_28.json\n",
      "Loading file: velo_event_29.json\n",
      "Loading file: velo_event_30.json\n",
      "Loading file: velo_event_31.json\n",
      "Loading file: velo_event_32.json\n",
      "Loading file: velo_event_33.json\n",
      "Loading file: velo_event_34.json\n",
      "Loading file: velo_event_35.json\n",
      "Loading file: velo_event_36.json\n",
      "Loading file: velo_event_37.json\n",
      "Loading file: velo_event_38.json\n",
      "Loading file: velo_event_39.json\n",
      "Loading file: velo_event_40.json\n",
      "Loading file: velo_event_41.json\n",
      "Loading file: velo_event_42.json\n",
      "Loading file: velo_event_43.json\n",
      "Loading file: velo_event_44.json\n",
      "Loading file: velo_event_45.json\n",
      "Loading file: velo_event_46.json\n",
      "Loading file: velo_event_47.json\n",
      "Loading file: velo_event_48.json\n",
      "Loading file: velo_event_49.json\n",
      "Loading file: velo_event_50.json\n",
      "Skipping problematic file: velo_event_51.json\n",
      "Loading file: velo_event_52.json\n",
      "Loading file: velo_event_53.json\n",
      "Loading file: velo_event_54.json\n",
      "Loading file: velo_event_55.json\n",
      "Loading file: velo_event_56.json\n",
      "Loading file: velo_event_57.json\n",
      "Loading file: velo_event_58.json\n",
      "Loading file: velo_event_59.json\n",
      "Loading file: velo_event_60.json\n",
      "Loading file: velo_event_61.json\n",
      "Loading file: velo_event_62.json\n",
      "Loading file: velo_event_63.json\n",
      "Loading file: velo_event_64.json\n",
      "Loading file: velo_event_65.json\n",
      "Loading file: velo_event_66.json\n",
      "Loading file: velo_event_67.json\n",
      "Loading file: velo_event_68.json\n",
      "Loading file: velo_event_69.json\n",
      "Loading file: velo_event_70.json\n",
      "Loading file: velo_event_71.json\n",
      "Loading file: velo_event_72.json\n",
      "Loading file: velo_event_73.json\n",
      "Loading file: velo_event_74.json\n",
      "Loading file: velo_event_75.json\n",
      "Loading file: velo_event_76.json\n",
      "Loading file: velo_event_77.json\n",
      "Loading file: velo_event_78.json\n",
      "Loading file: velo_event_79.json\n",
      "Loading file: velo_event_80.json\n",
      "Loading file: velo_event_81.json\n",
      "Loading file: velo_event_82.json\n",
      "Loading file: velo_event_83.json\n",
      "Loading file: velo_event_84.json\n",
      "Loading file: velo_event_85.json\n",
      "Loading file: velo_event_86.json\n",
      "Loading file: velo_event_87.json\n",
      "Loading file: velo_event_88.json\n",
      "Loading file: velo_event_89.json\n",
      "Loading file: velo_event_90.json\n",
      "Loading file: velo_event_91.json\n",
      "Loading file: velo_event_92.json\n",
      "Loading file: velo_event_93.json\n",
      "Loading file: velo_event_94.json\n",
      "Loading file: velo_event_95.json\n",
      "Loading file: velo_event_96.json\n",
      "Loading file: velo_event_97.json\n",
      "Loading file: velo_event_98.json\n",
      "Loading file: velo_event_99.json\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "n_files = 100\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data)\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_pipeline = TrackFollowingPipeline(events=events, intra_node=False)\n",
    "Graph_pipeline = GraphDFSPipeline(events=events, intra_node=False)\n",
    "Triplet_pipeline = SearchByTripletTriePipeline(events=events, intra_node=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = ParticleSwarm(\n",
    "    swarm_size = 20,\n",
    "    inertia = 0.5,\n",
    "    cognitive = 1.5,\n",
    "    social = 1.5,\n",
    "    max_iterations = 100,\n",
    "    objective = \"min\",\n",
    "    nested=False,\n",
    "    weights = [1.0, 1.0, -10.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 100/100 [01:59<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters_TF = TF_pipeline.optimise_parameters(Optimiser, max_runs=100) # DO NOT remove max_runs, chances are that this will run forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 10/10 [00:46<00:00,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters_Graph = Graph_pipeline.optimise_parameters(Optimiser, max_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters_Triplet = Triplet_pipeline.optimise_parameters(Optimiser, max_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(Optimiser.get_optimised_pMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(optimal_parameters_TF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
