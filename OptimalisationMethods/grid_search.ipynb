{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2fa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from velopix_wrappers.optimizers import BaseOptimizer, pMap\n",
    "from velopix_wrappers.velopix_pipeline import TrackFollowingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2f6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: strict\n",
    "from collections.abc import Generator\n",
    "from itertools import product\n",
    "from typing import Any, TypeAlias, cast, Literal\n",
    "from math import inf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "_Types: TypeAlias = bool | int | float\n",
    "HSpace: TypeAlias = Generator[pMap, None, None] # NOTE: Stands for \"hypothesis space\"\n",
    "\n",
    "class GridSearch(BaseOptimizer):\n",
    "    _resolution: int\n",
    "    _stopped: bool = False\n",
    "    _spgen: HSpace # NOTE: Stands for \"space generator\"\n",
    "    _options: dict[str, Any]\n",
    "    _total_hypotheses: int\n",
    "    _last_config: pMap\n",
    "    _best_config: pMap\n",
    "    _best_score: float\n",
    "\n",
    "    def __init__(self, resolution: int = 10, objective: Literal[\"min\", \"max\"] = \"min\", options: dict[str, Any] | None = None):\n",
    "        super().__init__(objective=objective)\n",
    "        self._resolution = resolution\n",
    "        self._options = options if options is not None else {\"w\": [1., 1., 1.], \"nested\": False}\n",
    "\n",
    "    def init(self) -> pMap:\n",
    "        \"\"\"\n",
    "        Initializes the optimization process by setting an initial parameter map.\n",
    "        \"\"\"\n",
    "        self._stopped = False\n",
    "\n",
    "        num_hypotheses = 1\n",
    "        axis: dict[str, tuple[_Types, ...]] = {}\n",
    "\n",
    "        for param, (dtype, _) in self._algorithm.get_config().items():\n",
    "            if dtype == bool:\n",
    "                axis[param] = (False, True)\n",
    "            elif dtype in (float, int):\n",
    "                low, high = cast(tuple[_Types, _Types], self._algorithm.get_bounds().get(param))\n",
    "                axis[param] = tuple(np.linspace(low, high, num=self._resolution, endpoint=True))\n",
    "                if dtype == int:\n",
    "                    axis[param] = tuple(frozenset(map(int, axis[param])))\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported type: {dtype}\")\n",
    "            num_hypotheses *= len(axis[param])\n",
    "            \n",
    "        def spgen() -> HSpace:\n",
    "            idx2axe = {i: a for i, a in enumerate(axis.keys())}\n",
    "            space = product(*[axis[idx2axe[i]] for i in range(len(axis))])\n",
    "            space = tuple(space)\n",
    "            self._total_hypotheses = len(space)\n",
    "            for point in space:\n",
    "                config = {idx2axe[i]: point[i] for i in range(len(point))}\n",
    "                self._last_config = config\n",
    "                yield config\n",
    "        \n",
    "        self._spgen = spgen()\n",
    "\n",
    "        self.best_score = inf if self.objective == \"min\" else -inf\n",
    "        try:\n",
    "            self.best_config = next(self._spgen)\n",
    "            return self.best_config\n",
    "        except StopIteration:\n",
    "            raise RuntimeError(\"No hypotheses generated.\")\n",
    "\n",
    "    def next(self) -> pMap:\n",
    "        \"\"\"\n",
    "        Generates the next parameter map by slightly modifying existing values.\n",
    "        \"\"\"\n",
    "        last_score = self.objective_func([1., 1., 1., -10.])\n",
    "\n",
    "        if self.objective == \"min\":\n",
    "            if last_score < self.best_score:\n",
    "                self.best_score = last_score\n",
    "                self.best_config = self._last_config\n",
    "        elif self.objective == \"max\":\n",
    "            if self.best_score < last_score:\n",
    "                self.best_score = last_score\n",
    "                self.best_config = self._last_config\n",
    "        try:\n",
    "            return next(self._spgen)\n",
    "        except StopIteration:\n",
    "            self._stopped = True\n",
    "            return self.best_config\n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if the optimization process is finished.\n",
    "        In this case, it stops after `max_iterations` iterations.\n",
    "        \"\"\"\n",
    "        return self._stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88716a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: velo_event_0.json\n",
      "Loading file: velo_event_1.json\n",
      "Loading file: velo_event_2.json\n",
      "Loading file: velo_event_3.json\n",
      "Loading file: velo_event_4.json\n",
      "Loading file: velo_event_5.json\n",
      "Loading file: velo_event_6.json\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "n_files = 7\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data) # type: ignore\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f1d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrackFollowingPipeline(events=events, intra_node=True) # type: ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25f4d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising: 100%|██████████| 243/243 [00:45<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "Optimiser = GridSearch(resolution=3)\n",
    "optimal_parameters = pipeline.optimise_parameters(Optimiser, max_runs=243) # DO NOT remove max_runs, chances are that this will run forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8c54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_slope': np.float64(1.0), 'y_slope': np.float64(1.0), 'x_tol': np.float64(0.8), 'y_tol': np.float64(0.8), 'scatter': np.float64(0.4)}\n"
     ]
    }
   ],
   "source": [
    "print(optimal_parameters) # Note these are just here for example..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
