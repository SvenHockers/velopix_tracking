{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from velopix_wrappers.parameter_optimisers import optimiserBase\n",
    "from velopix_wrappers.velopix_pipeline import TrackFollowingPipeline, GraphDFSPipeline, SearchByTripletTriePipeline\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the optimiser child class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "class BayesianOptimiser(optimiserBase):\n",
    "    def __init__(self, learning_rate, max_iterations=100, target_score=0.3):\n",
    "        super().__init__(auto_eval={\"autoEval\": True, \"nested\": False, \"weights\": [3,5,10]})\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.target_score = target_score\n",
    "        self.best_score = float(\"inf\")\n",
    "        self.current_iteration = 0\n",
    "\n",
    "        # To store previous evaluations\n",
    "        self.X = []  # Parameter sets (input)\n",
    "        self.Y = []  # Objective function results (output)\n",
    "\n",
    "        # Gaussian Process initialization\n",
    "        kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))\n",
    "        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "        \n",
    "\n",
    "    def init(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Initializes the optimization process by setting an initial parameter map.\n",
    "        \"\"\"\n",
    "        pMap = self._algorithm.get_config()  # Get a copy of the parameter schema\n",
    "\n",
    "        initial_param_set = {}\n",
    "\n",
    "        for key, (expected_type, _) in pMap.items():\n",
    "            if expected_type == float:\n",
    "                initial_param_set[key] = random.uniform(0, 1)  # Random float between 0 and 1\n",
    "            elif expected_type == int:\n",
    "                initial_param_set[key] = random.randint(0, 10)  # Random integer between 0 and 10\n",
    "            elif expected_type == bool:\n",
    "                initial_param_set[key] = random.choice([True, False])  # Random boolean\n",
    "            elif expected_type == list:\n",
    "                initial_param_set[key] = []  # Assign an empty list (or populate it if needed)\n",
    "\n",
    "        # Evaluate the initial point\n",
    "        self.X.append(list(initial_param_set.values()))\n",
    "        self.Y.append(self.objective_func(initial_param_set))\n",
    "\n",
    "        print(f\"Initial parameter set: {initial_param_set}\")\n",
    "\n",
    "        self.best_config = initial_param_set\n",
    "        \n",
    "\n",
    "        return initial_param_set\n",
    "\n",
    "    def next(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Uses Bayesian Optimization to generate the next parameter map by predicting the next best set.\n",
    "        \"\"\"\n",
    "        if len(self.X) > 1:\n",
    "            # Fit Gaussian Process model\n",
    "            self.gpr.fit(self.X, self.Y)\n",
    "\n",
    "        # Generate the next set of parameters using Bayesian Optimization\n",
    "        next_param_set = self._predict_next()\n",
    "\n",
    "        self.X.append(list(next_param_set.values()))  # Add the new point to X\n",
    "        self.Y.append(self.objective_func(next_param_set))  # Evaluate the next point and add to Y\n",
    "\n",
    "        return next_param_set\n",
    "\n",
    "    def _predict_next(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Predicts the next parameter set using the Gaussian Process model.\n",
    "        \"\"\"\n",
    "        # For simplicity, we'll randomly sample a set of points to evaluate and pick the one with the best acquisition value.\n",
    "        pMap = self._algorithm.get_config()\n",
    "        param_space = []\n",
    "\n",
    "        for key, (expected_type, _) in pMap.items():\n",
    "            low, high = self._algorithm.get_bounds().get(key)  \n",
    "            if expected_type == float:\n",
    "                # Sample a random float within the given bounds\n",
    "                param_space.append(np.random.uniform(low, high, 10))  # 10 random candidates between low and high\n",
    "            elif expected_type == int:\n",
    "                # Sample a random integer within the given bounds\n",
    "                param_space.append(np.random.randint(low, high + 1, 10))  # 10 random integers between low and high\n",
    "            elif expected_type == bool:\n",
    "                # Sample random booleans as before (since there are no bounds for booleans)\n",
    "                param_space.append(np.random.choice([True, False], size=10))  # 10 random booleans\n",
    "            elif expected_type == list:\n",
    "                # For lists, sample randomly if there are bounds\n",
    "                # This part may depend on how the bounds for lists are defined\n",
    "                param_space.append([np.random.randint(0, 10, size=np.random.randint(1, 5)) for _ in range(10)])  # 10 random lists\n",
    "\n",
    "        print(f\"temp param space: {param_space}\")\n",
    "\n",
    "        #TODO: Save best parameter set to self.best_config(?)\n",
    "\n",
    "        # Now you can use these candidates to query the acquisition function (simplified)\n",
    "        best_candidate = None\n",
    "        best_acquisition_value = float('inf')\n",
    "        \n",
    "        for candidate in self._generate_candidates(param_space):\n",
    "            X_candidate = np.array(candidate).reshape(1, -1)\n",
    "            acquisition_value = self._acquisition_function(X_candidate)\n",
    "            print(f\"acquisition_value\", acquisition_value)\n",
    "            if acquisition_value < best_acquisition_value:\n",
    "                best_candidate = candidate\n",
    "                best_acquisition_value = acquisition_value\n",
    "\n",
    "        # Convert the best candidate back into the parameter set format\n",
    "        pMap = self._algorithm.get_config()\n",
    "        next_param_set = {key: value for key, value in zip(pMap.keys(), best_candidate)}\n",
    "\n",
    "        print(f\"Next parameter set: {next_param_set}\")\n",
    "\n",
    "        return next_param_set\n",
    "\n",
    "    def _generate_candidates(self, param_space):\n",
    "        \"\"\"\n",
    "        Generates candidates from the parameter space.\n",
    "        \"\"\"\n",
    "        #TODO: In this case, we're just randomly sampling from the parameter space for simplicity\n",
    "        candidates = list(np.array(np.meshgrid(*param_space)).T.reshape(-1, len(param_space)))\n",
    "        return candidates\n",
    "\n",
    "    def _acquisition_function(self, X_candidate):\n",
    "        \"\"\"\n",
    "        Acquisition function to guide the optimization.\n",
    "        For simplicity, using a simple negative expected improvement here.\n",
    "        \"\"\"\n",
    "        mean, std = self.gpr.predict(X_candidate, return_std=True)\n",
    "        return -mean  # Expected improvement simplification: pick the most uncertain area\n",
    "\n",
    "    def objective_func(self, param_set: Dict[str, Any]) -> float:\n",
    "        \"\"\"\n",
    "        Converts the results of an experiment into a numeric score.\n",
    "        In this example, we simulate a loss function that we aim to minimize.\n",
    "        \"\"\"\n",
    "        # TODO: Fake evaluation function\n",
    "        # Use the actual parameters and compute the score from the experiment\n",
    "        return self.event_objective(self.weights)\n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if the optimization process is finished.\n",
    "        In this case, it stops after `max_iterations` iterations or the target score is reached.\n",
    "        \"\"\"\n",
    "        return self.best_score < self.target_score or self.current_iteration >= self.max_iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load event data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: velo_event_0.json\n",
      "Loading file: velo_event_1.json\n",
      "Loading file: velo_event_2.json\n",
      "Loading file: velo_event_3.json\n",
      "Loading file: velo_event_4.json\n",
      "Loading file: velo_event_5.json\n",
      "Loading file: velo_event_6.json\n",
      "Loading file: velo_event_7.json\n",
      "Loading file: velo_event_8.json\n",
      "Loading file: velo_event_9.json\n",
      "Loading file: velo_event_10.json\n",
      "Loading file: velo_event_11.json\n",
      "Loading file: velo_event_12.json\n",
      "Loading file: velo_event_13.json\n",
      "Loading file: velo_event_14.json\n",
      "Loading file: velo_event_15.json\n",
      "Loading file: velo_event_16.json\n",
      "Loading file: velo_event_17.json\n",
      "Loading file: velo_event_18.json\n",
      "Loading file: velo_event_19.json\n",
      "Loading file: velo_event_20.json\n",
      "Loading file: velo_event_21.json\n",
      "Loading file: velo_event_22.json\n",
      "Loading file: velo_event_23.json\n",
      "Loading file: velo_event_24.json\n",
      "Loading file: velo_event_25.json\n",
      "Loading file: velo_event_26.json\n",
      "Loading file: velo_event_27.json\n",
      "Loading file: velo_event_28.json\n",
      "Loading file: velo_event_29.json\n",
      "Loading file: velo_event_30.json\n",
      "Loading file: velo_event_31.json\n",
      "Loading file: velo_event_32.json\n",
      "Loading file: velo_event_33.json\n",
      "Loading file: velo_event_34.json\n",
      "Loading file: velo_event_35.json\n",
      "Loading file: velo_event_36.json\n",
      "Loading file: velo_event_37.json\n",
      "Loading file: velo_event_38.json\n",
      "Loading file: velo_event_39.json\n",
      "Loading file: velo_event_40.json\n",
      "Loading file: velo_event_41.json\n",
      "Loading file: velo_event_42.json\n",
      "Loading file: velo_event_43.json\n",
      "Loading file: velo_event_44.json\n",
      "Loading file: velo_event_45.json\n",
      "Loading file: velo_event_46.json\n",
      "Loading file: velo_event_47.json\n",
      "Loading file: velo_event_48.json\n",
      "Loading file: velo_event_49.json\n",
      "Loading file: velo_event_50.json\n",
      "Skipping problematic file: velo_event_51.json\n",
      "Loading file: velo_event_52.json\n",
      "Loading file: velo_event_53.json\n",
      "Loading file: velo_event_54.json\n",
      "Loading file: velo_event_55.json\n",
      "Loading file: velo_event_56.json\n",
      "Loading file: velo_event_57.json\n",
      "Loading file: velo_event_58.json\n",
      "Loading file: velo_event_59.json\n",
      "Loading file: velo_event_60.json\n",
      "Loading file: velo_event_61.json\n",
      "Loading file: velo_event_62.json\n",
      "Loading file: velo_event_63.json\n",
      "Loading file: velo_event_64.json\n",
      "Loading file: velo_event_65.json\n",
      "Loading file: velo_event_66.json\n",
      "Loading file: velo_event_67.json\n",
      "Loading file: velo_event_68.json\n",
      "Loading file: velo_event_69.json\n",
      "Loading file: velo_event_70.json\n",
      "Loading file: velo_event_71.json\n",
      "Loading file: velo_event_72.json\n",
      "Loading file: velo_event_73.json\n",
      "Loading file: velo_event_74.json\n",
      "Loading file: velo_event_75.json\n",
      "Loading file: velo_event_76.json\n",
      "Loading file: velo_event_77.json\n",
      "Loading file: velo_event_78.json\n",
      "Loading file: velo_event_79.json\n",
      "Loading file: velo_event_80.json\n",
      "Loading file: velo_event_81.json\n",
      "Loading file: velo_event_82.json\n",
      "Loading file: velo_event_83.json\n",
      "Loading file: velo_event_84.json\n",
      "Loading file: velo_event_85.json\n",
      "Loading file: velo_event_86.json\n",
      "Loading file: velo_event_87.json\n",
      "Loading file: velo_event_88.json\n",
      "Loading file: velo_event_89.json\n",
      "Loading file: velo_event_90.json\n",
      "Loading file: velo_event_91.json\n",
      "Loading file: velo_event_92.json\n",
      "Loading file: velo_event_93.json\n",
      "Loading file: velo_event_94.json\n",
      "Loading file: velo_event_95.json\n",
      "Loading file: velo_event_96.json\n",
      "Loading file: velo_event_97.json\n",
      "Loading file: velo_event_98.json\n",
      "Loading file: velo_event_99.json\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "n_files = 100\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data)\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrackFollowingPipeline(events=events, intra_node=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesianOptimiser' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m Optimiser = BayesianOptimiser(learning_rate=\u001b[32m0.05\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m optimal_parameters = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimise_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# DO NOT remove max_runs, chances are that this will run forever (NO, I do what I want :-|)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/velopix_pipeline.py:57\u001b[39m, in \u001b[36mPipelineBase.optimise_parameters\u001b[39m\u001b[34m(self, Optimiser, max_runs)\u001b[39m\n\u001b[32m     55\u001b[39m i = \u001b[32m0\u001b[39m\n\u001b[32m     56\u001b[39m finished = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28mself\u001b[39m.set_pMap([\u001b[43mOptimiser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=max_runs, desc=\u001b[33m\"\u001b[39m\u001b[33mOptimising\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:36\u001b[39m, in \u001b[36moptimiserBase.start\u001b[39m\u001b[34m(self, algorithm)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m, algorithm: ReconstructionAlgorithms) -> pMapType:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mself\u001b[39m._algorithm = algorithm \u001b[38;5;66;03m# this is required for the pMap validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     pMap = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.validate_config(pMap, \u001b[38;5;28mself\u001b[39m._algorithm.value):\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pMap\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mBayesianOptimiser.init\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Evaluate the initial point\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mself\u001b[39m.X.append(\u001b[38;5;28mlist\u001b[39m(initial_param_set.values()))\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28mself\u001b[39m.Y.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_param_set\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitial parameter set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_param_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.best_config = initial_param_set\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mBayesianOptimiser.objective_func\u001b[39m\u001b[34m(self, param_set)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03mConverts the results of an experiment into a numeric score.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03mIn this example, we simulate a loss function that we aim to minimize.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# TODO: Fake evaluation function\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Use the actual parameters and compute the score from the experiment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:90\u001b[39m, in \u001b[36moptimiserBase.event_objective\u001b[39m\u001b[34m(self, weights)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevent_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     validation_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_run_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     n_tracks: \u001b[38;5;28mint\u001b[39m = cast(\u001b[38;5;28mint\u001b[39m, validation_results.get(\u001b[33m\"\u001b[39m\u001b[33mtotal_tracks\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_tracks <= \u001b[32m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m\"\u001b[39m) * \u001b[38;5;28mself\u001b[39m._objective_factor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:58\u001b[39m, in \u001b[36moptimiserBase.get_run_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_run_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ValidationResults: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'BayesianOptimiser' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "Optimiser = BayesianOptimiser(learning_rate=0.05)\n",
    "optimal_parameters = pipeline.optimise_parameters(Optimiser, max_runs=10) # DO NOT remove max_runs, chances are that this will run forever (NO, I do what I want :-|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_slope': 0.2351038165663738, 'y_slope': 0.23103144358186567, 'x_tol': 0.08198982505358221, 'y_tol': 0.6830579745512162, 'scatter': 0.9865701772737444}\n"
     ]
    }
   ],
   "source": [
    "print(optimal_parameters) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
