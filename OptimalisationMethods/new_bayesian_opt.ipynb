{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from velopix_wrappers.parameter_optimisers import optimiserBase\n",
    "from velopix_wrappers.velopix_pipeline import TrackFollowingPipeline, GraphDFSPipeline, SearchByTripletTriePipeline\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from scipy.stats import norm \n",
    "\n",
    "class BayesianOptimiser(optimiserBase):\n",
    "    def __init__(self, learning_rate, n_candidates, acq_xi, acq_kappa, max_iterations=100, n_initial=5, seed=42):\n",
    "        super().__init__(Objective=\"min\", auto_eval={\"autoEval\": True, \"nested\": False, \"weights\": [3,5,10]})\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_initial  = n_initial\n",
    "        self.n_candidates = n_candidates\n",
    "        self.current_iteration = 0\n",
    "        self.max_iterations = max_iterations\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "\n",
    "        self.X = []  # Parameter sets (input)\n",
    "        self.Y = []  # Objective function results (output)\n",
    "\n",
    "        # Gaussian Process initialization\n",
    "        \n",
    "        kernel = C(1.0, (1e-4,1e1)) * RBF(1.0, (1e-4,1e1))\n",
    "        self.gpr = GaussianProcessRegressor(\n",
    "            kernel=kernel,\n",
    "            normalize_y=True,\n",
    "            alpha=1e-6,\n",
    "            n_restarts_optimizer=10,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        self.acq_xi = acq_xi\n",
    "        self.acq_kappa = acq_kappa\n",
    "    \n",
    "    def init(self) -> Dict[str, Any]:\n",
    "        \"\"\" \n",
    "        It provides the initial set of parameters to be evaluated. \n",
    "        This set is generated randomly within the bounds.\n",
    "        \"\"\"\n",
    "\n",
    "        params_config = self._algorithm.get_config()\n",
    "        bounds = self._algorithm.get_bounds()\n",
    "\n",
    "        param_map = {}\n",
    "\n",
    "        for key, (expected_type, _) in params_config.items():\n",
    "            low, high = bounds[key]\n",
    "            if expected_type is float:\n",
    "                param_map[key] = float(self.random_state.uniform(low, high))\n",
    "            elif expected_type is int:\n",
    "                param_map[key] = int(self.random_state.randint(low, high + 1))\n",
    "            elif expected_type is bool:\n",
    "                param_map[key] = bool(self.random_state.choice([False, True]))\n",
    "            elif expected_type is list:\n",
    "                param_map[key] = []  \n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported type: {type}\")\n",
    "        print(f\"Initial parameters: {param_map}\")\n",
    "        self.prev_config = param_map\n",
    "        return param_map\n",
    " \n",
    "    def add_run(self, results) -> None:\n",
    "        self.run = results\n",
    "        if self.auto_evaluate:\n",
    "            self._evaluate_run(weight=self.weights, nested=self.nested)\n",
    "        print(f\"Results: {results}\")\n",
    "\n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        if self.current_iteration >= self.max_iterations:\n",
    "            print(\"Max iterations reached. Stopping optimization.\")\n",
    "            return True\n",
    "    \n",
    "    def next(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        1) Record the last run’s data into X, Y\n",
    "        2) If <2 points, just sample a random map\n",
    "        3) Otherwise fit GP, score n_candidates by EI, pick best\n",
    "        4) Return the next param_map\n",
    "        \"\"\"\n",
    "        # 1) record last point\n",
    "        x_prev = self._dict_to_vector(self.prev_config)\n",
    "        print(f\"Previous parameters: {x_prev}\")\n",
    "        self.X.append(x_prev)\n",
    "        y_prev = self.score_history[-1]    # score just recorded by add_run()\n",
    "        self.Y.append(y_prev)\n",
    "\n",
    "        # 2) bootstrap with one more random draw\n",
    "        if len(self.X) < 2:\n",
    "            next_map = self._sample_random_map()\n",
    "        else:\n",
    "            # 3) fit GP\n",
    "            self.gpr.fit(np.vstack(self.X), np.array(self.Y))\n",
    "\n",
    "            # generate and score candidates\n",
    "            candidates = [self._sample_random_map() \n",
    "                          for _ in range(self.n_candidates)]\n",
    "            acq_vals = []\n",
    "            for pm in candidates:\n",
    "                x_c = self._dict_to_vector(pm)\n",
    "                mu, sigma = self.gpr.predict(x_c, return_std=True)\n",
    "                # Expected Improvement (EI) for minimization\n",
    "                z  = (self.best_score - mu) / sigma\n",
    "                ei = sigma * (z * norm.cdf(z) + norm.pdf(z))\n",
    "                acq_vals.append(ei)\n",
    "\n",
    "            # 4) pick best\n",
    "            best_idx = int(np.argmax(acq_vals))\n",
    "            next_map = candidates[best_idx]\n",
    "\n",
    "        # 5) update iteration count and prev_config\n",
    "        self.current_iteration += 1\n",
    "        self.prev_config = next_map\n",
    "        print(f\"Next parameters: {next_map}\")\n",
    "        return next_map\n",
    "\n",
    "    # You’ll also need these helpers (if you haven’t already):\n",
    "    def _sample_random_map(self) -> Dict[str,Any]:\n",
    "        schema = self._algorithm.get_config()\n",
    "        bounds = self._algorithm.get_bounds()\n",
    "        pm = {}\n",
    "        for key, (typ, _) in schema.items():\n",
    "            low, high = bounds[key]\n",
    "            if typ is float:\n",
    "                pm[key] = float(self.random_state.uniform(low,high))\n",
    "            elif typ is int:\n",
    "                pm[key] = int(self.random_state.randint(low, high+1))\n",
    "            elif typ is bool:\n",
    "                pm[key] = bool(self.random_state.choice([False,True]))\n",
    "            else:\n",
    "                pm[key] = []  # or your own logic for lists/categoricals\n",
    "        return pm\n",
    "\n",
    "    def _dict_to_vector(self, pm: Dict[str,Any]) -> np.ndarray:\n",
    "        schema = self._algorithm.get_config()\n",
    "        xs = []\n",
    "        for key, (typ, _) in schema.items():\n",
    "            v = pm[key]\n",
    "            if typ is bool:\n",
    "                xs.append(1.0 if v else 0.0)\n",
    "            elif typ in (int, float):\n",
    "                xs.append(float(v))\n",
    "            else:\n",
    "                xs.append(float(len(v)))  # e.g. length for lists\n",
    "        return np.array(xs).reshape(1,-1)\n",
    "    \n",
    "    def objective_func(self, w: list[float], nested: bool = False) -> float:\n",
    "        if nested:\n",
    "            return self.intra_event_objective(w)\n",
    "        return self.event_objective(w)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: velo_event_0.json\n",
      "Loading file: velo_event_1.json\n",
      "Loading file: velo_event_2.json\n",
      "Loading file: velo_event_3.json\n",
      "Loading file: velo_event_4.json\n",
      "Loading file: velo_event_5.json\n",
      "Loading file: velo_event_6.json\n",
      "Loading file: velo_event_7.json\n",
      "Loading file: velo_event_8.json\n",
      "Loading file: velo_event_9.json\n",
      "Loading file: velo_event_10.json\n",
      "Loading file: velo_event_11.json\n",
      "Loading file: velo_event_12.json\n",
      "Loading file: velo_event_13.json\n",
      "Loading file: velo_event_14.json\n",
      "Loading file: velo_event_15.json\n",
      "Loading file: velo_event_16.json\n",
      "Loading file: velo_event_17.json\n",
      "Loading file: velo_event_18.json\n",
      "Loading file: velo_event_19.json\n",
      "Loading file: velo_event_20.json\n",
      "Loading file: velo_event_21.json\n",
      "Loading file: velo_event_22.json\n",
      "Loading file: velo_event_23.json\n",
      "Loading file: velo_event_24.json\n",
      "Loading file: velo_event_25.json\n",
      "Loading file: velo_event_26.json\n",
      "Loading file: velo_event_27.json\n",
      "Loading file: velo_event_28.json\n",
      "Loading file: velo_event_29.json\n",
      "Loading file: velo_event_30.json\n",
      "Loading file: velo_event_31.json\n",
      "Loading file: velo_event_32.json\n",
      "Loading file: velo_event_33.json\n",
      "Loading file: velo_event_34.json\n",
      "Loading file: velo_event_35.json\n",
      "Loading file: velo_event_36.json\n",
      "Loading file: velo_event_37.json\n",
      "Loading file: velo_event_38.json\n",
      "Loading file: velo_event_39.json\n",
      "Loading file: velo_event_40.json\n",
      "Loading file: velo_event_41.json\n",
      "Loading file: velo_event_42.json\n",
      "Loading file: velo_event_43.json\n",
      "Loading file: velo_event_44.json\n",
      "Loading file: velo_event_45.json\n",
      "Loading file: velo_event_46.json\n",
      "Loading file: velo_event_47.json\n",
      "Loading file: velo_event_48.json\n",
      "Loading file: velo_event_49.json\n",
      "Loading file: velo_event_50.json\n",
      "Skipping problematic file: velo_event_51.json\n",
      "Loading file: velo_event_52.json\n",
      "Loading file: velo_event_53.json\n",
      "Loading file: velo_event_54.json\n",
      "Loading file: velo_event_55.json\n",
      "Loading file: velo_event_56.json\n",
      "Loading file: velo_event_57.json\n",
      "Loading file: velo_event_58.json\n",
      "Loading file: velo_event_59.json\n",
      "Loading file: velo_event_60.json\n",
      "Loading file: velo_event_61.json\n",
      "Loading file: velo_event_62.json\n",
      "Loading file: velo_event_63.json\n",
      "Loading file: velo_event_64.json\n",
      "Loading file: velo_event_65.json\n",
      "Loading file: velo_event_66.json\n",
      "Loading file: velo_event_67.json\n",
      "Loading file: velo_event_68.json\n",
      "Loading file: velo_event_69.json\n",
      "Loading file: velo_event_70.json\n",
      "Loading file: velo_event_71.json\n",
      "Loading file: velo_event_72.json\n",
      "Loading file: velo_event_73.json\n",
      "Loading file: velo_event_74.json\n",
      "Loading file: velo_event_75.json\n",
      "Loading file: velo_event_76.json\n",
      "Loading file: velo_event_77.json\n",
      "Loading file: velo_event_78.json\n",
      "Loading file: velo_event_79.json\n",
      "Loading file: velo_event_80.json\n",
      "Loading file: velo_event_81.json\n",
      "Loading file: velo_event_82.json\n",
      "Loading file: velo_event_83.json\n",
      "Loading file: velo_event_84.json\n",
      "Loading file: velo_event_85.json\n",
      "Loading file: velo_event_86.json\n",
      "Loading file: velo_event_87.json\n",
      "Loading file: velo_event_88.json\n",
      "Loading file: velo_event_89.json\n",
      "Loading file: velo_event_90.json\n",
      "Loading file: velo_event_91.json\n",
      "Loading file: velo_event_92.json\n",
      "Loading file: velo_event_93.json\n",
      "Loading file: velo_event_94.json\n",
      "Loading file: velo_event_95.json\n",
      "Loading file: velo_event_96.json\n",
      "Loading file: velo_event_97.json\n",
      "Loading file: velo_event_98.json\n",
      "Loading file: velo_event_99.json\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "n_files = 100\n",
    "\n",
    "for i in range(0, n_files):\n",
    "    if i == 51:\n",
    "        \"\"\"\n",
    "        There's an issue with event 51 -> module_prefix_sum contains value 79 twice resulting in and indexing error when loading the event\n",
    "        \"\"\"\n",
    "        print(f\"Skipping problematic file: velo_event_{i}.json\")\n",
    "    else:    \n",
    "        print(f\"Loading file: velo_event_{i}.json\")\n",
    "        event_file = open(os.path.join(\"../DB/raw\", f\"velo_event_{i}.json\"))\n",
    "        json_data = json.loads(event_file.read())\n",
    "        events.append(json_data)\n",
    "        event_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load event data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: {'x_slope': 0.3191210094715857, 'y_slope': 0.9150354205589739, 'x_tol': 0.5810088531405578, 'y_tol': 0.6371303162093983, 'scatter': 0.335646984499045}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimising:   0%|          | 0/10 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BayesianOptimiser' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = TrackFollowingPipeline(events=events, intra_node=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      2\u001b[39m Optimiser = BayesianOptimiser(learning_rate=\u001b[32m0.05\u001b[39m, max_iterations=\u001b[32m100\u001b[39m, n_candidates=\u001b[32m5\u001b[39m, acq_xi=\u001b[32m0.01\u001b[39m, acq_kappa=\u001b[32m1.96\u001b[39m, n_initial=\u001b[32m5\u001b[39m, seed=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m optimal_parameters = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimise_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# DO NOT remove max_runs, chances are that this will run forever (NO, I do what I want :-|)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/velopix_pipeline.py:61\u001b[39m, in \u001b[36mPipelineBase.optimise_parameters\u001b[39m\u001b[34m(self, Optimiser, max_runs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.run(overwrite=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[43mOptimiser\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     finished = Optimiser.is_finished()\n\u001b[32m     63\u001b[39m     i += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:53\u001b[39m, in \u001b[36moptimiserBase.add_run\u001b[39m\u001b[34m(self, results)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: ValidationResults) -> \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_evaluate:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m.run = results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:112\u001b[39m, in \u001b[36moptimiserBase._evaluate_run\u001b[39m\u001b[34m(self, weight, nested)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m], nested: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m score == \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mScore is null\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m.score_history.append(score)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 150\u001b[39m, in \u001b[36mBayesianOptimiser.objective_func\u001b[39m\u001b[34m(self, w, nested)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nested:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.intra_event_objective(w)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:90\u001b[39m, in \u001b[36moptimiserBase.event_objective\u001b[39m\u001b[34m(self, weights)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevent_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     validation_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_run_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     n_tracks: \u001b[38;5;28mint\u001b[39m = cast(\u001b[38;5;28mint\u001b[39m, validation_results.get(\u001b[33m\"\u001b[39m\u001b[33mtotal_tracks\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_tracks <= \u001b[32m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m\"\u001b[39m) * \u001b[38;5;28mself\u001b[39m._objective_factor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/velopix_tracking/velopix_wrappers/parameter_optimisers.py:58\u001b[39m, in \u001b[36moptimiserBase.get_run_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_run_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ValidationResults: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'BayesianOptimiser' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "pipeline = TrackFollowingPipeline(events=events, intra_node=False)\n",
    "Optimiser = BayesianOptimiser(learning_rate=0.05, max_iterations=100, n_candidates=5, acq_xi=0.01, acq_kappa=1.96, n_initial=5, seed=None)\n",
    "optimal_parameters = pipeline.optimise_parameters(Optimiser, max_runs=10) # DO NOT remove max_runs, chances are that this will run forever (NO, I do what I want :-|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'x_slope': 0.5700103267037683, 'y_slope': 0.24124649990096503, 'x_tol': 0.42154328464175794, 'y_tol': 0.4524089914293094, 'scatter': 0.24767414959260253}\n",
      "Best objective score: 63.84538962043942\n"
     ]
    }
   ],
   "source": [
    "best_params = Optimiser.get_optimised_pMap()\n",
    "\n",
    "best_params = Optimiser.best_config\n",
    "best_score  = Optimiser.best_score\n",
    "\n",
    "print(\"Best parameters found:\", best_params)\n",
    "print(\"Best objective score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
