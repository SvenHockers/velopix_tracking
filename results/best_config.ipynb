{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5419aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import Any, Literal\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d02cefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(file_name: str) -> pd.DataFrame:\n",
    "    records = []\n",
    "    with open(f\"./results/{file_name}\", 'r') as f:\n",
    "        buffer = []\n",
    "        depth = 0\n",
    "\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue  # skip blank lines\n",
    "\n",
    "            # Track nesting of braces\n",
    "            depth += line.count('{')\n",
    "            depth -= line.count('}')\n",
    "\n",
    "            buffer.append(raw)\n",
    "            # If weâ€™ve closed all opened braces, process one full JSON object\n",
    "            if depth == 0 and buffer:\n",
    "                chunk = ''.join(buffer)\n",
    "                obj = json.loads(chunk)\n",
    "                # same flattening logic as before\n",
    "                for uid, details in obj.items():\n",
    "                    params = details.pop('params')\n",
    "                    flat = {'id': uid, **details}\n",
    "                    for p, v in params.items():\n",
    "                        if isinstance(v, list) and len(v) == 2:\n",
    "                            flat[f'{p}_x'] = v[0]\n",
    "                            flat[f'{p}_y'] = v[1]\n",
    "                        else:\n",
    "                            flat[p] = v\n",
    "                    records.append(flat)\n",
    "                buffer = []\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad6311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_result(df_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Find the index of the row with the lowest score\n",
    "    best_index = df_results['score'].idxmin()\n",
    "    # Return the row as a DataFrame\n",
    "    return df_results.loc[[best_index]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07a47d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_config(file_name: str) -> dict[str, Any]:\n",
    "    stem = Path(file_name).stem            \n",
    "    config_name = stem.removeprefix(\"result_\")      \n",
    "    \n",
    "    config_path = Path(\"configurations\") / f\"{config_name}.json\"\n",
    "    \n",
    "    # 3) Open & load the JSON\n",
    "    with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        config = json.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b9d267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(file_name: str) -> pd.DataFrame:\n",
    "    config = _get_config(file_name)\n",
    "    solver: str = config[\"solverName\"]\n",
    "    algorithm: str = config[\"reconstruction_algo\"]\n",
    "    options = {option: [value] for option, value in config[\"optimizer\"].items() if option not in (\"objective\", \"nested\", \"weights\")}\n",
    "    weigths = {f\"weight_{i}\": [w] for i, w in enumerate(config[\"optimizer\"][\"weights\"])}\n",
    "    return pd.DataFrame({\"solver\": [solver],\n",
    "                        \"algorithm\": [algorithm],\n",
    "                        \"hyperparams\": [{\"solver\": solver,**{k: v[0] for k, v in options.items()}}],\n",
    "                        **options,\n",
    "                        **weigths}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9feda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(file_name: str) -> pd.DataFrame:\n",
    "    df_results = parse_results(file_name)\n",
    "    best_params = pick_best_result(df_results)\n",
    "    df_config = parse_config(file_name)\n",
    "    \n",
    "    # Combine the best parameters with the configuration\n",
    "    combined_df = pd.concat([df_config, best_params], axis=1)\n",
    "    \n",
    "    # Add the file name as a new column\n",
    "    combined_df['file_name'] = file_name\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f42cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments_with(algorithm: Literal[\"TF\", \"ST\", \"GDFS\"], weights: tuple[float, float, float, float]) -> pd.DataFrame:\n",
    "    results_dir = Path(\"./results\")\n",
    "    all_files = [f for f in results_dir.glob(\"*.jsonl\") if f.is_file()]\n",
    "    \n",
    "    all_experiments: list[Any] = []\n",
    "    for file in all_files:\n",
    "        config = _get_config(file.name)\n",
    "        if config[\"reconstruction_algo\"] == algorithm and tuple(config[\"optimizer\"][\"weights\"]) == weights:\n",
    "            df_experiment = load_experiment(file.name)\n",
    "            all_experiments.append(df_experiment)\n",
    "\n",
    "    return pd.concat(all_experiments, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3eec8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_k_config(df_experiments: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    # Sort by score (ascending) and take the top k rows\n",
    "    sorted_df = df_experiments.sort_values('score', ascending=True)\n",
    "    # Return the top k rows as a DataFrame\n",
    "    return sorted_df.head(k).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f94fb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'{\"solver\": \"GridSearch\", \"resolution\": 10}': 4}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments: list[dict[str, Any]] = [\n",
    "    {\"algorithm\": \"ST\", \"weights\": (0.1, 0.3, 0.5, -10.0)},\n",
    "    {\"algorithm\": \"ST\", \"weights\": (0.01, 0.5, 0.5, -7.0)},\n",
    "    {\"algorithm\": \"ST\", \"weights\": (0.4, 0.2, 0.5, -7.0)},\n",
    "    {\"algorithm\": \"ST\", \"weights\": (0.4, 0.2, 0.3, -5.0)},\n",
    "]\n",
    "success_counts = {}\n",
    "for experiment in experiments:\n",
    "    df_experiments = load_experiments_with(experiment[\"algorithm\"], experiment[\"weights\"])\n",
    "    top_1 = pick_top_k_config(df_experiments, 1)\n",
    "    top_1 = best_config.dropna(axis=1)\n",
    "    hkey = json.dumps(top_1.iloc[0]['hyperparams'])\n",
    "    success_counts[hkey] = success_counts.get(hkey, 0) + 1\n",
    "success_counts\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
